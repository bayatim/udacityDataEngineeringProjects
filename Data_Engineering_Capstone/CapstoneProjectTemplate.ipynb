{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "## Data Engineering Capstone Project\n",
    "\n",
    "### Project Summary\n",
    "* The goal of this project is to evaluate the impact of weather's temperature on immagrants movements over April, 2016 in USA\n",
    "* Apache Spark is used to extract and transform raw data, and make a datawarehouse in parquet file format. \n",
    "* The star schema is used to develop a database, which will be effectively used for handling analytical queries.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "-- Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "* This project extracts raw data from two sources as described below. \n",
    "* It creates a datamodel of immagrants' movement in US consistsing of one fact tables referencing two dimension tables.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "-- Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "##### I94 Immigration Data: \n",
    "* This data comes from the [US National Tourism and Trade Office](https://travel.trade.gov/research/reports/i94/historical/2016.html).\n",
    "* Dataset includes infoes on individual incomming immigrants and thei ports on entry. \n",
    "* Data dictionary: I94_SAS_Labels_Descriptions.SAS\n",
    "* Sample file: immigration_data_sample.csv\n",
    "* Columns:\n",
    "    * 'i94yr   ':  '4 digit year',\n",
    "    * 'i94mon  ':  'Numeric month',\n",
    "    * 'i94addr ':  'where the immigrants resides in USA',\n",
    "\n",
    "##### World Temperature Data:\n",
    "* This dataset comes from [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "* Dataset includes infoe on temprature on cities globally. This project only uses data of US cities.\n",
    "* Columns:\n",
    "    * 'dt',\n",
    "    * 'AverageTemperature',\n",
    "    * 'City',\n",
    "    * 'Country',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# do all imports and installs here\n",
    "import pandas as pd\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "import datetime\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.dataframe as psd\n",
    "import pyspark.sql.session as pss\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from utils.city_code import city_code\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define reader class to handel reading and writting data\n",
    "class Reader:\n",
    "    \"\"\"[Reader class loads raw data for further usage. It is written with Singleton pattern to prevent loading data\n",
    "    multiple time, as the process is very slow.]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [the instance of class]\n",
    "    \"\"\"\n",
    "    _instance = None\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        \"\"\"[initializes a new instance of class if not existed. It initializes parameters, creates a spark session, loads data]\n",
    "\n",
    "        Returns:\n",
    "            [type]: [inputpath, output path, spark session, and data]\n",
    "        \"\"\"\n",
    "        if not cls._instance:\n",
    "            # create inatance\n",
    "            spark_reader = super(Reader, cls).__new__(cls, *args, **kwargs)\n",
    "            # fit parameters and data\n",
    "            spark_reader.fit()\n",
    "            cls._instance = spark_reader\n",
    "        \n",
    "        return cls._instance\n",
    "        \n",
    "    def parameters(self) -> str:\n",
    "        \"\"\"[initializes necessary parameters]\n",
    "\n",
    "        Returns:\n",
    "            [str]: [path to read and write data]\n",
    "        \"\"\"\n",
    "        # data sources\n",
    "        paths = {\n",
    "                \"i94immigration\" : \"./datasources/i94immigration\",\n",
    "                \"worldtemperature\" : \"./datasources/worldtemperature\"\n",
    "                }\n",
    "        return paths\n",
    "        \n",
    "    def create_spark_session(self) -> pss.SparkSession: \n",
    "        \"\"\"[initialize a spark session]\n",
    "\n",
    "        Returns:\n",
    "            [pyspark.sql.session.SparkSession]: [created spark session]\n",
    "        \"\"\"\n",
    "        # build spark session\n",
    "        spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    "            .enableHiveSupport() \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        return spark\n",
    "\n",
    "    def from_anyformat_to_parquet(self):\n",
    "        # Read raw data and load them into parquet files\n",
    "        if not os.path.exists(self.paths['i94immigration']):\n",
    "            logging.info(\"start transfering i94 immigration raw data\")\n",
    "            df_immigration_spark = self.spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "            df_immigration_spark.write.parquet(self.paths['i94immigration'])\n",
    "            logging.info(\"i94 immigration raw data are written into parquet files\")\n",
    "        else:\n",
    "            logging.info(\"i94 immigration raw data are are already written into parquet files\")\n",
    "            \n",
    "        if not os.path.exists(self.paths['worldtemperature']):\n",
    "            logging.info(\"start transfering world temperature raw data\")\n",
    "            df_worldtemperature_spark =self.spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv', header=True)\n",
    "            df_worldtemperature_spark.write.parquet(self.paths['worldtemperature'])\n",
    "            logging.info(\"world temperature raw data are written into parquet files\")\n",
    "        else:\n",
    "            logging.info(\"world temperature raw data are are already written into parquet files\")\n",
    "            \n",
    "    \n",
    "    def load_i94immigration_data(self) -> psd.DataFrame:\n",
    "        \"\"\"[loads i94 immigration data]\n",
    "\n",
    "        Returns:\n",
    "            [pyspark.sql.dataframe.DataFrame]: [i94 immigration data as spark dataframe]\n",
    "        \"\"\"\n",
    "        # read immigration data\n",
    "        immigration_df = self.spark.read.parquet(self.paths['i94immigration'])\n",
    "\n",
    "        return immigration_df\n",
    "\n",
    "\n",
    "    def load_worldtemperature_data(self) -> psd.DataFrame:\n",
    "        \"\"\"[loads world temperature data]\n",
    "\n",
    "        Returns:\n",
    "            [pyspark.sql.dataframe.DataFrame]: [world temperature data as spark dataframe]\n",
    "        \"\"\"\n",
    "        # read world temprature data\n",
    "        temperature_df = self.spark.read.parquet(self.paths['worldtemperature'])\n",
    "\n",
    "        return temperature_df\n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\"[fits necessary parameters, creats spark session, and loads i94immigration and worldtemperature data.]\n",
    "\n",
    "        Returns:\n",
    "            [type]: []\n",
    "        \"\"\"\n",
    "\n",
    "        logging.info(\"geting root paths to read and write data\")\n",
    "        self.paths = self.parameters()\n",
    "        \n",
    "        logging.info(\"getting spark session\")\n",
    "        self.spark = self.create_spark_session()\n",
    "        \n",
    "        logging.info(\"stage raw data into parquet files if not already exist!!!\")\n",
    "        self.from_anyformat_to_parquet()\n",
    "        \n",
    "        logging.info(\"Start fitting i94immigration data to reader class ...\")\n",
    "        self.immigration_df = self.load_i94immigration_data()\n",
    "        print(\"End fitting i94immigration data to reader class!\")\n",
    "        \n",
    "        print(\"Start fitting worldtemperature data to reader class ...\")\n",
    "        self.temperature_df = self.load_worldtemperature_data()\n",
    "        print(\"End fitting worldtemperature data to reader class!\")\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:geting root paths to read and write data\n",
      "INFO:root:getting spark session\n",
      "INFO:root:stage raw data into parquet files if not already exist!!!\n",
      "INFO:root:i94 immigration raw data are are already written into parquet files\n",
      "INFO:root:world temperature raw data are are already written into parquet files\n",
      "INFO:root:Start fitting i94immigration data to reader class ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End fitting i94immigration data to reader class!\n",
      "Start fitting worldtemperature data to reader class ...\n",
      "End fitting worldtemperature data to reader class!\n"
     ]
    }
   ],
   "source": [
    "reader = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|\n",
      "|5748520.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     F|  null|     DL|9.495645143E10|00040|      B1|\n",
      "|5748521.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  28.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1988.0|10292016|     M|  null|     DL|9.495638813E10|00040|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader.immigration_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader.temperature_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Wrangling: Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def filter_immigration_data():\n",
    "    # select needed columns\n",
    "    immigration_usa_df = reader.immigration_df.select(['i94yr', 'i94mon', 'i94addr', 'i94port'])\n",
    "    return immigration_usa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_usa_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>i94port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>HHW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>HHW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>HHW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>HOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i94yr  i94mon i94addr i94port\n",
       "0  2016.0     4.0      CA     LOS\n",
       "1  2016.0     4.0      NV     LOS\n",
       "2  2016.0     4.0      WA     LOS\n",
       "3  2016.0     4.0      WA     LOS\n",
       "4  2016.0     4.0      WA     LOS\n",
       "5  2016.0     4.0      HI     HHW\n",
       "6  2016.0     4.0      HI     HHW\n",
       "7  2016.0     4.0      HI     HHW\n",
       "8  2016.0     4.0      FL     HOU\n",
       "9  2016.0     4.0      CA     LOS"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_usa_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create view for immigration data\n",
    "immigration_usa_df.createOrReplaceTempView('immigration_usa_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# count unique values in a given spark sql table\n",
    "def value_counts(table, col):\n",
    "    return reader.spark.sql(f\"\"\"\n",
    "    select {col}, count({col}) as count\n",
    "    from {table}\n",
    "    group by {col}\n",
    "    order by count\n",
    "    \"\"\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "| i94yr|  count|\n",
      "+------+-------+\n",
      "|2016.0|3096313|\n",
      "+------+-------+\n",
      "\n",
      "+------+-------+\n",
      "|i94mon|  count|\n",
      "+------+-------+\n",
      "|   4.0|3096313|\n",
      "+------+-------+\n",
      "\n",
      "+-------+-----+\n",
      "|i94addr|count|\n",
      "+-------+-----+\n",
      "|   null|    0|\n",
      "|     KF|    1|\n",
      "|     52|    1|\n",
      "|     71|    1|\n",
      "|     S6|    1|\n",
      "|     85|    1|\n",
      "|     UL|    1|\n",
      "|     RU|    1|\n",
      "|     VL|    1|\n",
      "|     RA|    1|\n",
      "|     UR|    1|\n",
      "|     ZN|    1|\n",
      "|     TC|    1|\n",
      "|     PD|    1|\n",
      "|     YH|    1|\n",
      "|     EX|    1|\n",
      "|     RF|    1|\n",
      "|     RO|    1|\n",
      "|     73|    1|\n",
      "|     FC|    1|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+-----+\n",
      "|i94port|count|\n",
      "+-------+-----+\n",
      "|    PHF|    1|\n",
      "|    NC8|    1|\n",
      "|    CNC|    1|\n",
      "|    VNB|    1|\n",
      "|    COO|    1|\n",
      "|    ERC|    1|\n",
      "|    CPX|    1|\n",
      "|    PCF|    1|\n",
      "|    LWT|    1|\n",
      "|    NIG|    1|\n",
      "|    MAI|    1|\n",
      "|    RIO|    1|\n",
      "|    HNN|    1|\n",
      "|    YIP|    1|\n",
      "|    ANA|    1|\n",
      "|    SCH|    1|\n",
      "|    BWM|    1|\n",
      "|    REN|    1|\n",
      "|    MND|    1|\n",
      "|    BHX|    2|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts('immigration_usa_table', 'i94yr')\n",
    "value_counts('immigration_usa_table', 'i94mon')\n",
    "value_counts('immigration_usa_table', 'i94addr')\n",
    "value_counts('immigration_usa_table', 'i94port')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* The above descriptive results show that both 'i94yr' and 'i94mon' columns are clean, but there are lots of invalid codes in 'i94addr' and 'i94port' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_valid_ports():\n",
    "    # Extract valid ports into a dictionary\n",
    "    re_obj = re.compile(\"'(.*)'\\s=\\s'(.*)'\") # '(\\S{3})'\\s=\\s'(.*),\\s{1}(\\S{2}).*\n",
    "    validPorts = {}\n",
    "    with open('utils/port_code.py') as f:\n",
    "         for data in f:\n",
    "             match = re_obj.search(data)\n",
    "             if match:\n",
    "                 validPorts[match[1]] = match[2].strip()\n",
    "    return validPorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* We assumed that all immigrants came to the US on the first day of a given month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_immigration_data(validPorts):\n",
    "    # select needed columns\n",
    "    immigration_usa_df = reader.immigration_df.select(['i94yr', 'i94mon', 'i94addr', 'i94port'])  \n",
    "\n",
    "    # cast cities that are valid\n",
    "    valid_city_code = list(set(city_code.keys()))\n",
    "    str_valid_city_code = str(valid_city_code).replace('[', '(').replace(']', ')')\n",
    "\n",
    "    # cast ports that are valid\n",
    "    valid_port_code = list(set(validPorts.keys()))\n",
    "    str_valid_port_code = str(valid_port_code).replace('[', '(').replace(']', ')')\n",
    "\n",
    "\n",
    "    clean_immigration_usa_df = reader.spark.sql(f\"\"\"\n",
    "    select date(concat(cast(i94yr as int), '-', cast(i94mon as int), '-01')) as dt, cast(i94addr as varchar(2)), cast(i94port as varchar(3))\n",
    "    from immigration_usa_table\n",
    "    where i94yr is not null and i94mon is not null and i94addr is not null and i94port is not null and\n",
    "    i94addr in {str_valid_city_code} and i94port in {str_valid_port_code} \n",
    "    \"\"\")\n",
    "    \n",
    "    return clean_immigration_usa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "validPorts = get_valid_ports()\n",
    "clean_immigration_usa_df = clean_immigration_data(validPorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: date (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_immigration_usa_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create a view of clean immigration data\n",
    "clean_immigration_usa_df.createOrReplaceTempView('clean_immigration_usa_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|i94addr|count|\n",
      "+-------+-----+\n",
      "|     99|   52|\n",
      "|     VI|  226|\n",
      "|     WY|  460|\n",
      "|     SD|  557|\n",
      "|     WV|  808|\n",
      "|     ND| 1225|\n",
      "|     MT| 1339|\n",
      "|     VT| 1477|\n",
      "|     AK| 1604|\n",
      "|     ID| 1752|\n",
      "|     MS| 1771|\n",
      "|     NM| 1994|\n",
      "|     ME| 2361|\n",
      "|     NH| 2817|\n",
      "|     AR| 2873|\n",
      "|     DE| 3111|\n",
      "|     KS| 3224|\n",
      "|     OK| 3239|\n",
      "|     RI| 3289|\n",
      "|     IA| 3391|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+-----+\n",
      "|i94port|count|\n",
      "+-------+-----+\n",
      "|    FRI|    1|\n",
      "|    VNB|    1|\n",
      "|    HNN|    1|\n",
      "|    NC8|    1|\n",
      "|    SPO|    1|\n",
      "|    RIO|    1|\n",
      "|    CPX|    1|\n",
      "|    MGM|    1|\n",
      "|    BWM|    1|\n",
      "|    NIG|    1|\n",
      "|    ANA|    1|\n",
      "|    LWT|    1|\n",
      "|    PHF|    1|\n",
      "|    YIP|    1|\n",
      "|    MND|    1|\n",
      "|    PSM|    2|\n",
      "|    ADW|    2|\n",
      "|    NOO|    2|\n",
      "|    SGJ|    2|\n",
      "|    MTH|    2|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts('clean_immigration_usa_table', 'i94addr')\n",
    "value_counts('clean_immigration_usa_table', 'i94port')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Wrangling: Temperature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* We only focus on data from usa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* As the immigration data is from 2016 we only select temperature data as close to this year as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def filter_temperature_data():\n",
    "    temperature_df = reader.temperature_df\n",
    "    temperature_usa_df = temperature_df.where(temperature_df.Country == 'United States')\n",
    "    temperature_usa_df = temperature_usa_df.select(['dt', 'Country', 'City', 'AverageTemperature'])\n",
    "\n",
    "    temperature_usa_df = temperature_usa_df.withColumn('dt', F.to_date('dt', 'yyyy-MM-dd'))\n",
    "    temperature_usa_df = temperature_usa_df.where((temperature_usa_df['dt'] >= '2013-04-01') & (temperature_usa_df['dt'] < '2013-05-01'))\n",
    "    \n",
    "    return temperature_usa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_usa_df = filter_temperature_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|        dt|count|\n",
      "+----------+-----+\n",
      "|2013-04-01|  257|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_usa_df.groupBy('dt').count().show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: date (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_usa_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>AverageTemperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>15.752999999999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Akron</td>\n",
       "      <td>9.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>11.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>12.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Allentown</td>\n",
       "      <td>9.722999999999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Amarillo</td>\n",
       "      <td>12.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Anaheim</td>\n",
       "      <td>15.380999999999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>-6.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Ann Arbor</td>\n",
       "      <td>6.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Antioch</td>\n",
       "      <td>15.995999999999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt        Country         City  AverageTemperature\n",
       "0  2013-04-01  United States      Abilene  15.752999999999998\n",
       "1  2013-04-01  United States        Akron               9.691\n",
       "2  2013-04-01  United States  Albuquerque              11.555\n",
       "3  2013-04-01  United States   Alexandria              12.425\n",
       "4  2013-04-01  United States    Allentown   9.722999999999999\n",
       "5  2013-04-01  United States     Amarillo              12.954\n",
       "6  2013-04-01  United States      Anaheim  15.380999999999998\n",
       "7  2013-04-01  United States    Anchorage              -6.421\n",
       "8  2013-04-01  United States    Ann Arbor               6.819\n",
       "9  2013-04-01  United States      Antioch  15.995999999999999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_usa_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|AverageTemperature|\n",
      "+-------+------------------+\n",
      "|  count|               257|\n",
      "|   mean| 13.75025680933851|\n",
      "| stddev| 5.253205757503348|\n",
      "|    min|            -0.591|\n",
      "|    max| 9.722999999999999|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_usa_df.select(['AverageTemperature']).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "for col in temperature_usa_df.columns: value_counts('temperature_usa_table', col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Adding i94port column to temprature dataframe. It is mapped from cleaned up immigration dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@F.udf\n",
    "def get_port(city):\n",
    "    for key in validPorts:\n",
    "        if city.lower() in validPorts[key].lower():\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_temerature_usa_data(temperature_usa_df):\n",
    "    temperature_usa_df = temperature_usa_df.withColumn('i94port', get_port(temperature_usa_df['City']))\n",
    "    temperature_usa_df.createOrReplaceTempView('temperature_usa_table')\n",
    "\n",
    "    clean_temperature_usa_df = reader.spark.sql(\"\"\"\n",
    "    select date(dt) as dt, cast(Country as varchar(13)), cast(City as string), round(AverageTemperature, 2) as AverageTemperature, cast(i94port as varchar(3))\n",
    "    from temperature_usa_table\n",
    "    where dt is not null and Country is not null and City is not null and  AverageTemperature is not null and i94port is not null\n",
    "    \"\"\")\n",
    "    \n",
    "    return clean_temperature_usa_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_temperature_usa_df = clean_temerature_usa_data(temperature_usa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_temerature_usa_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "* **Data model**:\n",
    "    * The star schema is used as datamodel of this project.\n",
    "    * It is a relational model contains one fact table named fact_table surrounded by two dimension tables named dim_immigration_table and dim_temperature_table.\n",
    "    * It suits analytical queries and user can analyze the data with few number of joins.\n",
    "\n",
    "\n",
    "* **Fact table** - dim_immigration table joined with the dim_temperature table on i94port and dt, Columns:\n",
    "    * dt - timestamp of arrival,\n",
    "    * i94port: 3 character code of destination USA city,\n",
    "    * AverageTemperature: average temperature of destination city\n",
    "\n",
    "\n",
    "* **Immigration dimension table**:\n",
    "    * dt - timestamp of arrival,\n",
    "    * i194addr: where the immigrants resides in USA (2 character code),\n",
    "    * i94port = 3 character code of destination USA city\n",
    "\n",
    "\n",
    "* **Temperature dimension table**:\n",
    "    * dt: timestamp\n",
    "    * AverageTemperature: average temperature\n",
    "    * City: city name\n",
    "    * Country: country name\n",
    "    * i94port: 3 character code of destination city (extracted from i94-immigration data)\n",
    "\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filter\n",
    "immigration_usa_df = filter_immigration_data()\n",
    "\n",
    "# create view for immigration data\n",
    "immigration_usa_df.createOrReplaceTempView('immigration_usa_table')\n",
    "\n",
    "# clean\n",
    "validPorts = get_valid_ports()\n",
    "clean_immigration_usa_df = clean_immigration_data(validPorts)\n",
    "\n",
    "# load\n",
    "clean_immigration_usa_df.write.mode(\"overwrite\").partitionBy(\"i94port\").parquet(\"/output_data/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filter\n",
    "temperature_usa_df = filter_temperature_data()\n",
    "\n",
    "# clean\n",
    "clean_temperature_usa_df = clean_temerature_usa_data(temperature_usa_df)\n",
    "\n",
    "# load\n",
    "clean_temperature_usa_df.write.mode(\"overwrite\").partitionBy(\"i94port\").parquet(\"/output_data/temprature.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create a view of clean immigration data\n",
    "clean_immigration_usa_df.createOrReplaceTempView('clean_immigration_usa_table')\n",
    "# create\n",
    "clean_temperature_usa_df.createOrReplaceTempView('clean_temperature_usa_table')\n",
    "# fact\n",
    "fact_df = spark.sql('''\n",
    "select  im.dt                  AS dt,\n",
    "        im.i94port             AS i94port,\n",
    "        t.AverageTemperature   AS AverageTemperature\n",
    "from clean_immigration_usa_table AS im\n",
    "JOIN clean_temperature_usa_table AS t \n",
    "ON im.i94port = t.i94port\n",
    "''')\n",
    "\n",
    "# create\n",
    "fact_df.createOrReplaceTempView('fact_table')\n",
    "\n",
    "# load\n",
    "fact_df.write.mode(\"overwrite\").partitionBy(\"i94port\").parquet(\"/output_data/fact.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "from typing import List\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "def data_quality_check(tables: List[str]=None):\n",
    "    for table in tables:\n",
    "        logging.info(f'Running data quality check on table {table}')\n",
    "\n",
    "        logging.info(f'Getting number of entries in table {table}')\n",
    "        records = spark.sql(f\"\"\"select count(*) as entries from {table}\"\"\").toPandas().entries.tolist()\n",
    "        logging.info(f'Table {table} has {records} numbers of entries.')\n",
    "\n",
    "        if not records or len(records) < 1 or records[0] < 1:\n",
    "            self.log.error(f\"Data quality check failed for table {table}\")\n",
    "            raise ValueError(f\"Data quality check failed for table {table}\")\n",
    "\n",
    "        logging.info(f\"Data quality check passed for table {table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running data quality check on table clean_immigration_usa_table\n",
      "INFO:root:Getting number of entries in table clean_immigration_usa_table\n",
      "INFO:root:Table clean_immigration_usa_table has [2917199] numbers of entries.\n",
      "INFO:root:Data quality check passed for table clean_immigration_usa_table\n",
      "INFO:root:Running data quality check on table clean_temperature_usa_table\n",
      "INFO:root:Getting number of entries in table clean_temperature_usa_table\n",
      "INFO:root:Table clean_temperature_usa_table has [117] numbers of entries.\n",
      "INFO:root:Data quality check passed for table clean_temperature_usa_table\n",
      "INFO:root:Running data quality check on table fact_table\n",
      "INFO:root:Getting number of entries in table fact_table\n",
      "INFO:root:Table fact_table has [2454343] numbers of entries.\n",
      "INFO:root:Data quality check passed for table fact_table\n"
     ]
    }
   ],
   "source": [
    "data_quality_check(['clean_immigration_usa_table', 'clean_temperature_usa_table', 'fact_table'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
