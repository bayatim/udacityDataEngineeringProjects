{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "* The goal of this project is to (1) evaluate the impact of weather's temperature on tourist movements in USA, and (2)\n",
    "    predict the number of visitores in upcoming monthes based on historical data\n",
    "* The star schema is used to develop a database, which will be effectively used for handling analytical queries.\n",
    "* Data pipelines\n",
    "* Spark!, and other tools\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "* consistsing of two? fact tables referencing two dimension tables.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "* Data come from the [US National Tourism and Trade Office](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) and Kaggle, [world temprature](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Datasets\n",
    "# I94 Immigration Data: \n",
    "    * This data comes from the US National Tourism and Trade Office.\n",
    "    * A data dictionary is included in the workspace.\n",
    "    * This is where the data comes from. https://travel.trade.gov/research/reports/i94/historical/2016.html\n",
    "    * There's a sample file so you can take a look at the data in csv format before reading it all in.\n",
    "    * You do not have to use the entire dataset, just use what you need to accomplish the goal you set at the beginning of the project.\n",
    "    \n",
    "    'i94yr   ':  '4 digit year',\n",
    "    'i94mon  ':  'Numeric month',\n",
    "    'i94addr ':  'where the immigrants resides in USA',\n",
    "\n",
    "# World Temperature Data:\n",
    "    This dataset came from Kaggle.\n",
    "    You can read more about it here. https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data\n",
    "    \n",
    "    'dt',\n",
    "    'AverageTemperature',\n",
    "    'City',\n",
    "    'Country',\n",
    "\n",
    "# U.S. City Demographic Data:\n",
    "    This data comes from OpenSoft.\n",
    "    You can read more about it here. https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/\n",
    "\n",
    "# Airport Code Table:\n",
    "    This is a simple table of airport codes and corresponding cities.\n",
    "    It comes from here. https://datahub.io/core/airport-codes#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pyspark.sql.functions as F\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet --> to be done once only\n",
    "#df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "#df_spark.write.parquet(\"sas_data2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|\n",
      "|5748520.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     F|  null|     DL|9.495645143E10|00040|      B1|\n",
      "|5748521.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  28.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1988.0|10292016|     M|  null|     DL|9.495638813E10|00040|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read immigration data\n",
    "immigration_df = spark.read.parquet(\"sas_data2\")\n",
    "immigration_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read world temprature data\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_df = spark.read.csv(fname, header=True)\n",
    "temperature_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Wrangling: Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_usa_df = immigration_df.select(['i94yr', 'i94mon', 'i94addr', 'i94port'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_usa_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>i94port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>HHW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>HHW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>HHW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>HOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i94yr  i94mon i94addr i94port\n",
       "0  2016.0     4.0      CA     LOS\n",
       "1  2016.0     4.0      NV     LOS\n",
       "2  2016.0     4.0      WA     LOS\n",
       "3  2016.0     4.0      WA     LOS\n",
       "4  2016.0     4.0      WA     LOS\n",
       "5  2016.0     4.0      HI     HHW\n",
       "6  2016.0     4.0      HI     HHW\n",
       "7  2016.0     4.0      HI     HHW\n",
       "8  2016.0     4.0      FL     HOU\n",
       "9  2016.0     4.0      CA     LOS"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_usa_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "|summary|  i94yr| i94mon|\n",
      "+-------+-------+-------+\n",
      "|  count|3096313|3096313|\n",
      "|   mean| 2016.0|    4.0|\n",
      "| stddev|    0.0|    0.0|\n",
      "|    min| 2016.0|    4.0|\n",
      "|    max| 2016.0|    4.0|\n",
      "+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_usa_df.select(['i94yr', 'i94mon']).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_usa_df.createOrReplaceTempView('immigration_usa_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def value_counts(table, col):\n",
    "    return spark.sql(f\"\"\"\n",
    "    select {col}, count({col}) as count\n",
    "    from {table}\n",
    "    group by {col}\n",
    "    order by count\n",
    "    \"\"\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "| i94yr|  count|\n",
      "+------+-------+\n",
      "|2016.0|3096313|\n",
      "+------+-------+\n",
      "\n",
      "+------+-------+\n",
      "|i94mon|  count|\n",
      "+------+-------+\n",
      "|   4.0|3096313|\n",
      "+------+-------+\n",
      "\n",
      "+-------+-----+\n",
      "|i94addr|count|\n",
      "+-------+-----+\n",
      "|   null|    0|\n",
      "|     KF|    1|\n",
      "|     52|    1|\n",
      "|     71|    1|\n",
      "|     S6|    1|\n",
      "|     85|    1|\n",
      "|     UL|    1|\n",
      "|     RU|    1|\n",
      "|     VL|    1|\n",
      "|     RA|    1|\n",
      "|     UR|    1|\n",
      "|     ZN|    1|\n",
      "|     TC|    1|\n",
      "|     PD|    1|\n",
      "|     YH|    1|\n",
      "|     EX|    1|\n",
      "|     RF|    1|\n",
      "|     RO|    1|\n",
      "|     73|    1|\n",
      "|     FC|    1|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+-----+\n",
      "|i94port|count|\n",
      "+-------+-----+\n",
      "|    PHF|    1|\n",
      "|    NC8|    1|\n",
      "|    CNC|    1|\n",
      "|    VNB|    1|\n",
      "|    COO|    1|\n",
      "|    ERC|    1|\n",
      "|    CPX|    1|\n",
      "|    PCF|    1|\n",
      "|    LWT|    1|\n",
      "|    NIG|    1|\n",
      "|    MAI|    1|\n",
      "|    RIO|    1|\n",
      "|    HNN|    1|\n",
      "|    YIP|    1|\n",
      "|    ANA|    1|\n",
      "|    SCH|    1|\n",
      "|    BWM|    1|\n",
      "|    REN|    1|\n",
      "|    MND|    1|\n",
      "|    BHX|    2|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts('immigration_usa_table', 'i94yr')\n",
    "value_counts('immigration_usa_table', 'i94mon')\n",
    "value_counts('immigration_usa_table', 'i94addr')\n",
    "value_counts('immigration_usa_table', 'i94port')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* The above descriptive results show that both 'i94yr' and 'i94mon' columns are clean, but there are lots of invalid codes in 'i94addr' and 'i94port' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract valid ports into a dictionary\n",
    "re_obj = re.compile(\"'(.*)'\\s=\\s'(.*)'\") # '(\\S{3})'\\s=\\s'(.*),\\s{1}(\\S{2}).*\n",
    "validPorts = {}\n",
    "with open('utils/port_code.py') as f:\n",
    "     for data in f:\n",
    "         match = re_obj.search(data)\n",
    "         if match:\n",
    "             validPorts[match[1]] = match[2].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cast cities that are valid\n",
    "from utils.city_code import city_code\n",
    "valid_city_code = list(set(city_code.keys()))\n",
    "str_valid_city_code = str(valid_city_code).replace('[', '(').replace(']', ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cast ports that are valid\n",
    "valid_port_code = list(set(validPorts.keys()))\n",
    "str_valid_port_code = str(valid_port_code).replace('[', '(').replace(']', ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* We assumed that all immigrants came to the US on the first day of a given month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_immigration_usa_df = spark.sql(f\"\"\"\n",
    "select date(concat(cast(i94yr as int), '-', cast(i94mon as int), '-01')) as dt, cast(i94addr as varchar(2)), cast(i94port as varchar(3))\n",
    "from immigration_usa_table\n",
    "where i94yr is not null and i94mon is not null and i94addr is not null and i94port is not null and\n",
    "i94addr in {str_valid_city_code} and i94port in {str_valid_port_code} \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: date (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_immigration_usa_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_immigration_usa_df.createOrReplaceTempView('clean_immigration_usa_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|i94addr|count|\n",
      "+-------+-----+\n",
      "|     99|   52|\n",
      "|     VI|  226|\n",
      "|     WY|  460|\n",
      "|     SD|  557|\n",
      "|     WV|  808|\n",
      "|     ND| 1225|\n",
      "|     MT| 1339|\n",
      "|     VT| 1477|\n",
      "|     AK| 1604|\n",
      "|     ID| 1752|\n",
      "|     MS| 1771|\n",
      "|     NM| 1994|\n",
      "|     ME| 2361|\n",
      "|     NH| 2817|\n",
      "|     AR| 2873|\n",
      "|     DE| 3111|\n",
      "|     KS| 3224|\n",
      "|     OK| 3239|\n",
      "|     RI| 3289|\n",
      "|     IA| 3391|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+-----+\n",
      "|i94port|count|\n",
      "+-------+-----+\n",
      "|    FRI|    1|\n",
      "|    VNB|    1|\n",
      "|    HNN|    1|\n",
      "|    NC8|    1|\n",
      "|    SPO|    1|\n",
      "|    RIO|    1|\n",
      "|    CPX|    1|\n",
      "|    MGM|    1|\n",
      "|    BWM|    1|\n",
      "|    NIG|    1|\n",
      "|    ANA|    1|\n",
      "|    LWT|    1|\n",
      "|    PHF|    1|\n",
      "|    YIP|    1|\n",
      "|    MND|    1|\n",
      "|    PSM|    2|\n",
      "|    ADW|    2|\n",
      "|    NOO|    2|\n",
      "|    SGJ|    2|\n",
      "|    MTH|    2|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts('clean_immigration_usa_table', 'i94addr')\n",
    "value_counts('clean_immigration_usa_table', 'i94port')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Wrangling: Temprature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* We only focus on data from usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_usa_df = temperature_df.where(temperature_df.Country == 'United States')\n",
    "temperature_usa_df = temperature_usa_df.select(['dt', 'Country', 'City', 'AverageTemperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* As the immigration data is from 2016 we only select temperature data as close to this year as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_usa_df = temperature_usa_df.withColumn('dt', F.to_date('dt', 'yyyy-MM-dd'))\n",
    "temperature_usa_df = temperature_usa_df.where((temperature_usa_df['dt'] >= '2013-04-01') & (temperature_usa_df['dt'] < '2013-05-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|        dt|count|\n",
      "+----------+-----+\n",
      "|2013-04-01|  257|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_usa_df.groupBy('dt').count().show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: date (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_usa_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>AverageTemperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>15.752999999999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Akron</td>\n",
       "      <td>9.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>11.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>12.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Allentown</td>\n",
       "      <td>9.722999999999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Amarillo</td>\n",
       "      <td>12.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Anaheim</td>\n",
       "      <td>15.380999999999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>-6.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Ann Arbor</td>\n",
       "      <td>6.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>United States</td>\n",
       "      <td>Antioch</td>\n",
       "      <td>15.995999999999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt        Country         City  AverageTemperature\n",
       "0  2013-04-01  United States      Abilene  15.752999999999998\n",
       "1  2013-04-01  United States        Akron               9.691\n",
       "2  2013-04-01  United States  Albuquerque              11.555\n",
       "3  2013-04-01  United States   Alexandria              12.425\n",
       "4  2013-04-01  United States    Allentown   9.722999999999999\n",
       "5  2013-04-01  United States     Amarillo              12.954\n",
       "6  2013-04-01  United States      Anaheim  15.380999999999998\n",
       "7  2013-04-01  United States    Anchorage              -6.421\n",
       "8  2013-04-01  United States    Ann Arbor               6.819\n",
       "9  2013-04-01  United States      Antioch  15.995999999999999"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_usa_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|AverageTemperature|\n",
      "+-------+------------------+\n",
      "|  count|               257|\n",
      "|   mean|13.750256809338524|\n",
      "| stddev|  5.25320575750335|\n",
      "|    min|            -0.591|\n",
      "|    max| 9.722999999999999|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_usa_df.select(['AverageTemperature']).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Adding i94port column to temprature dataframe. It is mapped from cleaned up immigration dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@F.udf\n",
    "def get_port(city):\n",
    "    for key in validPorts:\n",
    "        if city.lower() in validPorts[key].lower():\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_usa_df = temperature_usa_df.withColumn('i94port', get_port(temperature_usa_df['City']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_usa_df.createOrReplaceTempView('temperature_usa_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|        dt|count|\n",
      "+----------+-----+\n",
      "|2013-04-01|  257|\n",
      "+----------+-----+\n",
      "\n",
      "+-------------+-----+\n",
      "|      Country|count|\n",
      "+-------------+-----+\n",
      "|United States|  257|\n",
      "+-------------+-----+\n",
      "\n",
      "+---------------+-----+\n",
      "|           City|count|\n",
      "+---------------+-----+\n",
      "|    Chattanooga|    1|\n",
      "|      Worcester|    1|\n",
      "|     Charleston|    1|\n",
      "|          Tempe|    1|\n",
      "|         Corona|    1|\n",
      "|North Las Vegas|    1|\n",
      "|       Thornton|    1|\n",
      "|        Phoenix|    1|\n",
      "|      Hollywood|    1|\n",
      "| Pembroke Pines|    1|\n",
      "|       Savannah|    1|\n",
      "|     Toms River|    1|\n",
      "|  Coral Springs|    1|\n",
      "|          Omaha|    1|\n",
      "|      Anchorage|    1|\n",
      "|       Paradise|    1|\n",
      "|      Allentown|    1|\n",
      "|   Fort Collins|    1|\n",
      "|        Anaheim|    1|\n",
      "|     Greensboro|    1|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------------+-----+\n",
      "|AverageTemperature|count|\n",
      "+------------------+-----+\n",
      "|             17.16|    1|\n",
      "|            21.193|    1|\n",
      "|             2.543|    1|\n",
      "|15.752999999999998|    1|\n",
      "|            13.546|    1|\n",
      "|             9.264|    1|\n",
      "|            18.971|    1|\n",
      "|            18.677|    1|\n",
      "|            14.939|    1|\n",
      "|            10.119|    1|\n",
      "|13.040999999999999|    1|\n",
      "| 6.652000000000001|    1|\n",
      "|             19.09|    1|\n",
      "|            18.158|    1|\n",
      "|              6.93|    1|\n",
      "|            13.341|    1|\n",
      "|            -0.591|    1|\n",
      "|16.741999999999994|    1|\n",
      "|20.666999999999998|    1|\n",
      "|            12.308|    1|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+-----+\n",
      "|i94port|count|\n",
      "+-------+-----+\n",
      "|   null|    0|\n",
      "|    BUR|    1|\n",
      "|    SNA|    1|\n",
      "|    GRB|    1|\n",
      "|    RIV|    1|\n",
      "|    OAK|    1|\n",
      "|    DET|    1|\n",
      "|    RFD|    1|\n",
      "|    CID|    1|\n",
      "|    TAC|    1|\n",
      "|    OTM|    1|\n",
      "|    NSV|    1|\n",
      "|    SFR|    1|\n",
      "|    AFW|    1|\n",
      "|    JER|    1|\n",
      "|    BHX|    1|\n",
      "|    LLB|    1|\n",
      "|    SAV|    1|\n",
      "|    HAR|    1|\n",
      "|    NOG|    1|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in temperature_usa_df.columns: value_counts('temperature_usa_table', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_temperature_usa_df = spark.sql(\"\"\"\n",
    "select date(dt) as dt, cast(Country as varchar(13)), cast(City as string), round(AverageTemperature, 2) as AverageTemperature, cast(i94port as varchar(3))\n",
    "from temperature_usa_table\n",
    "where dt is not null and Country is not null and City is not null and  AverageTemperature is not null and i94port is not null\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_temperature_usa_df.createOrReplaceTempView('clean_temperature_usa_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "* **Data model**:\n",
    "    * The star schema is used as datamodel of this project.\n",
    "    * It is a relational model contains one fact table named fact_table surrounded by two dimension tables named dim_immigration_table and dim_temperature_table.\n",
    "    * It suits analytical queries and user can analyze the data with few number of joins.\n",
    "\n",
    "\n",
    "* **Fact table** - dim_immigration table joined with the dim_temperature table on i94port and dt, Columns:\n",
    "    * dt - timestamp of arrival,\n",
    "    * i94port: 3 character code of destination USA city,\n",
    "    * AverageTemperature: average temperature of destination city\n",
    "\n",
    "\n",
    "* **Immigration dimension table**:\n",
    "    * dt - timestamp of arrival,\n",
    "    * i194addr: where the immigrants resides in USA (2 character code),\n",
    "    * i94port = 3 character code of destination USA city\n",
    "\n",
    "\n",
    "* **Temperature dimension table**:\n",
    "    * dt: timestamp\n",
    "    * AverageTemperature: average temperature\n",
    "    * City: city name\n",
    "    * Country: country name\n",
    "    * i94port: 3 character code of destination city (extracted from i94-immigration data)\n",
    "\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_immigration_usa_df.write.mode(\"overwrite\").partitionBy(\"i94port\").parquet(\"/output_data/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_temperature_usa_df.write.mode(\"overwrite\").partitionBy(\"i94port\").parquet(\"/output_data/temprature.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_df = spark.sql('''\n",
    "select  im.dt                  AS dt,\n",
    "        im.i94port             AS i94port,\n",
    "        t.AverageTemperature   AS AverageTemperature\n",
    "from clean_immigration_usa_table AS im\n",
    "JOIN clean_temperature_usa_table AS t \n",
    "ON im.i94port = t.i94port\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+------------------+\n",
      "|        dt|i94port|AverageTemperature|\n",
      "+----------+-------+------------------+\n",
      "|2016-04-01|    ABQ|             11.56|\n",
      "|2016-04-01|    ABQ|             11.56|\n",
      "|2016-04-01|    ABQ|             11.56|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "|2016-04-01|    AXB|             12.43|\n",
      "+----------+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_table_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_df.write.mode(\"overwrite\").partitionBy(\"i94port\").parquet(\"/output_data/fact.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_df.createOrReplaceTempView('fact_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "from typing import List\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "def data_quality_check(tables: List[str]=None):\n",
    "    for table in tables:\n",
    "        logging.info(f'Running data quality check on table {table}')\n",
    "\n",
    "        logging.info(f'Getting number of entries in table {table}')\n",
    "        records = spark.sql(f\"\"\"select count(*) as entries from {table}\"\"\").toPandas().entries.tolist()\n",
    "        logging.info(f'Table {table} has {records} numbers of entries.')\n",
    "\n",
    "        if not records or len(records) < 1 or records[0] < 1:\n",
    "            self.log.error(f\"Data quality check failed for table {table}\")\n",
    "            raise ValueError(f\"Data quality check failed for table {table}\")\n",
    "\n",
    "        logging.info(f\"Data quality check passed for table {table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running data quality check on table clean_immigration_usa_table\n",
      "INFO:root:Getting number of entries in table clean_immigration_usa_table\n",
      "INFO:root:Table clean_immigration_usa_table has [2917199] numbers of entries.\n",
      "INFO:root:Data quality check passed for table clean_immigration_usa_table\n",
      "INFO:root:Running data quality check on table clean_temperature_usa_table\n",
      "INFO:root:Getting number of entries in table clean_temperature_usa_table\n",
      "INFO:root:Table clean_temperature_usa_table has [117] numbers of entries.\n",
      "INFO:root:Data quality check passed for table clean_temperature_usa_table\n",
      "INFO:root:Running data quality check on table fact_table\n",
      "INFO:root:Getting number of entries in table fact_table\n",
      "INFO:root:Table fact_table has [2454343] numbers of entries.\n",
      "INFO:root:Data quality check passed for table fact_table\n"
     ]
    }
   ],
   "source": [
    "data_quality_check(['clean_immigration_usa_table', 'clean_temperature_usa_table', 'fact_table'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
